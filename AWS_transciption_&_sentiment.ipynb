{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AWS Transcript & sentiment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO1XptUTT3/beHzOKhCPFGO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitsrivastava637/AWS-speech-to-text-AllenNLP-sentiment-detection/blob/main/AWS_transciption_%26_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wjW2pTlHse_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-cK55uBBoHd",
        "outputId": "693f4861-fb66-4188-9699-2dba72eb9db2"
      },
      "source": [
        "#!pip install boto3\n",
        "#!pip install allennlp_models\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "import boto3\n",
        "from urllib.request import urlopen\n",
        "import datetime\n",
        "import json\n",
        "from allennlp_models.pretrained import load_predictor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def amazon_transcribe_multi(audio_file_name,s3_link, max_speakers = None):\n",
        " \n",
        "    if max_speakers > 10:\n",
        "        raise ValueError(\"Maximum detected speakers is 10.\")\n",
        " \n",
        "    job_uri = s3_link\n",
        "    job_name = (audio_file_name.split('.')[0]).replace(\" \", \"\").replace(\"(\", \"\").replace(\")\", \"\") + str(time.time() * 1000) \n",
        "  \n",
        "    # check if name is taken or not\n",
        "    #job_name = check_job_name(job_name)\n",
        "  \n",
        "    if max_speakers != -1:\n",
        "        transcribe.start_transcription_job(\n",
        "          TranscriptionJobName=job_name,\n",
        "          Media={'MediaFileUri': job_uri},\n",
        "          MediaFormat=audio_file_name.split('.')[1],\n",
        "          IdentifyLanguage = True,\n",
        "          #LanguageOptions = [\"en-IN\", \"hi-IN\"],\n",
        "          Settings = {'ShowSpeakerLabels': True,\n",
        "                  'MaxSpeakerLabels': max_speakers\n",
        "                  }\n",
        "          )\n",
        "    else: \n",
        "        transcribe.start_transcription_job(\n",
        "           TranscriptionJobName=job_name,\n",
        "           Media={'MediaFileUri': job_uri},\n",
        "           MediaFormat=audio_file_name.split('.')[1],\n",
        "           IdentifyLanguage = True,\n",
        "           #LanguageOptions = [\"en-IN\", \"hi-IN\"],\n",
        "           Settings = {'ShowSpeakerLabels': True\n",
        "                  }\n",
        "           )    \n",
        "  \n",
        "    while True:\n",
        "        result = transcribe.get_transcription_job(TranscriptionJobName=job_name)\n",
        "        if result['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n",
        "            #print('not yet ready')\n",
        "            break\n",
        "        time.sleep(15)\n",
        "\n",
        "    if result['TranscriptionJob']['TranscriptionJobStatus'] == 'COMPLETED':\n",
        "        #print('your transcript is ready') \n",
        "        #data = pd.read_json(result['TranscriptionJob']['Transcript']['TranscriptFileUri'])\n",
        "        transcript_uri = urlopen(result[\"TranscriptionJob\"][\"Transcript\"][\"TranscriptFileUri\"])\n",
        "        transcript_json = json.dumps(json.load(transcript_uri))\n",
        "        print(\"transcription done\")\n",
        "    return transcript_json\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def read_output(filename, transcript_json):\n",
        "\n",
        "\n",
        "  # Create an output txt file\n",
        "    print(filename+'.txt')\n",
        "    with open(filename+'.txt','w') as w:\n",
        "\n",
        "        data=json.loads(transcript_json)\n",
        "        labels = data['results']['speaker_labels']['segments']\n",
        "        speaker_start_times={}\n",
        "      \n",
        "        for label in labels:\n",
        "            for item in label['items']:\n",
        "                speaker_start_times[item['start_time']] = item['speaker_label']\n",
        "\n",
        "        items = data['results']['items']\n",
        "        lines = []\n",
        "        line = ''\n",
        "        time = 0\n",
        "        speaker = 'null'\n",
        "        i = 0\n",
        "\n",
        "        # loop through all elements\n",
        "        for item in items:\n",
        "            i = i+1\n",
        "            content = item['alternatives'][0]['content']\n",
        "\n",
        "        # if it's starting time\n",
        "            if item.get('start_time'):\n",
        "                current_speaker = speaker_start_times[item['start_time']]\n",
        "        \n",
        "           # in AWS output, there are types as punctuation\n",
        "            elif item['type'] == 'punctuation':\n",
        "                line = line + content\n",
        "\n",
        "           # handle different speaker\n",
        "            if current_speaker != speaker:\n",
        "                if speaker:\n",
        "                    lines.append({'speaker':speaker, 'line':line, 'time':time})\n",
        "                line = content\n",
        "                speaker = current_speaker\n",
        "                time = item['start_time']\n",
        "          \n",
        "            elif item['type'] != 'punctuation':\n",
        "                line = line + ' ' + content\n",
        "        lines.append({'speaker': speaker, 'line': line,'time': time})\n",
        "        #lines.append({'line': line,'time': time})\n",
        "\n",
        "\n",
        "        # sort the results by the time\n",
        "        sorted_lines = sorted(lines,key=lambda k: float(k['time']))\n",
        "\n",
        "        uncleaned_line = ''\n",
        "\n",
        "        #write the lines in file \n",
        "        for line_data in sorted_lines:\n",
        "                line = '[' + str(datetime.timedelta(seconds=int(round(float(line_data['time']))))) + '] ' + line_data.get('speaker') + ': ' + line_data.get('line')\n",
        "                #line = '[' + str(datetime.timedelta(seconds=int(round(float(line_data['time']))))) + '] ' + ': ' + line_data.get('line')\n",
        "                uncleaned_line = uncleaned_line + line + '\\n\\n'\n",
        "                w.write(line + '\\n\\n')\n",
        "        \n",
        "        read = pd.DataFrame()\n",
        "\n",
        "        #read the lines in a dataframe format\n",
        "        for line in uncleaned_line:\n",
        "        # look at line in loop\n",
        "          read = read.append({'all_data' : line}, \n",
        "                ignore_index = True)\n",
        "\n",
        "        \n",
        "        \n",
        "        #This section will give all the text conversations between all speakers at a single place in the variable 'conversation' \n",
        "        conversation = ''\n",
        "        for i in range(len(read)):\n",
        "          spk_1_str = str(read.values[i])\n",
        "\n",
        "          #for speaker 0 \n",
        "          try:\n",
        "            spk1_str_f = spk_1_str.partition(\"spk_0\")[2].replace(\":\", \"\").replace(\"]\", \"\").replace('\\\\n', \"\")\n",
        "            spk1_str_f = spk1_str_f.rstrip(spk1_str_f[-1])\n",
        "            conversation = conversation + spk1_str_f\n",
        "          except:\n",
        "            pass\n",
        "          \n",
        "          #for speaker 1 \n",
        "          try:\n",
        "            spk1_str_f = spk_1_str.partition(\"spk_1\")[2].replace(\":\", \"\").replace(\"]\", \"\").replace('\\\\n', \"\")\n",
        "            spk1_str_f = spk1_str_f.rstrip(spk1_str_f[-1])\n",
        "            conversation = conversation + spk1_str_f\n",
        "          except:\n",
        "            pass\n",
        "          \n",
        "          #for speaker 2 : if he/she exists\n",
        "          try:\n",
        "            spk1_str_f = spk_1_str.partition(\"spk_2\")[2].replace(\":\", \"\").replace(\"]\", \"\").replace('\\\\n', \"\")\n",
        "            spk1_str_f = spk1_str_f.rstrip(spk1_str_f[-1])\n",
        "            conversation = conversation + spk1_str_f\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "          #for speaker 3 : if he/she exists\n",
        "          try:\n",
        "            spk1_str_f = spk_1_str.partition(\"spk_3\")[2].replace(\":\", \"\").replace(\"]\", \"\").replace('\\\\n', \"\")\n",
        "            spk1_str_f = spk1_str_f.rstrip(spk1_str_f[-1])\n",
        "            conversation = conversation + spk1_str_f\n",
        "          except:\n",
        "            pass  \n",
        "\n",
        "          #for speaker 4 : if he/she exists\n",
        "          try:\n",
        "            spk1_str_f = spk_1_str.partition(\"spk_4\")[2].replace(\":\", \"\").replace(\"]\", \"\").replace('\\\\n', \"\")\n",
        "            spk1_str_f = spk1_str_f.rstrip(spk1_str_f[-1])\n",
        "            conversation = conversation + spk1_str_f\n",
        "          except:\n",
        "            pass  \n",
        "\n",
        "          #for speaker 5 : if he/she exists\n",
        "          try:\n",
        "            spk1_str_f = spk_1_str.partition(\"spk_5\")[2].replace(\":\", \"\").replace(\"]\", \"\").replace('\\\\n', \"\")\n",
        "            spk1_str_f = spk1_str_f.rstrip(spk1_str_f[-1])\n",
        "            conversation = conversation + spk1_str_f\n",
        "          except:\n",
        "            pass   \n",
        "\n",
        "          #for speaker 6 : if he/she exists\n",
        "          try:\n",
        "            spk1_str_f = spk_1_str.partition(\"spk_6\")[2].replace(\":\", \"\").replace(\"]\", \"\").replace('\\\\n', \"\")\n",
        "            spk1_str_f = spk1_str_f.rstrip(spk1_str_f[-1])\n",
        "            conversation = conversation + spk1_str_f\n",
        "          except:\n",
        "            pass \n",
        "\n",
        "          #for speaker 7 : if he/she exists\n",
        "          try:\n",
        "            spk1_str_f = spk_1_str.partition(\"spk_7\")[2].replace(\":\", \"\").replace(\"]\", \"\").replace('\\\\n', \"\")\n",
        "            spk1_str_f = spk1_str_f.rstrip(spk1_str_f[-1])\n",
        "            conversation = conversation + spk1_str_f\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "          #for speaker 8 : if he/she exists\n",
        "          try:\n",
        "            spk1_str_f = spk_1_str.partition(\"spk_8\")[2].replace(\":\", \"\").replace(\"]\", \"\").replace('\\\\n', \"\")\n",
        "            spk1_str_f = spk1_str_f.rstrip(spk1_str_f[-1])\n",
        "            conversation = conversation + spk1_str_f\n",
        "          except:\n",
        "            pass\n",
        "\n",
        "          #for speaker 9 : if he/she exists\n",
        "          try:\n",
        "            spk1_str_f = spk_1_str.partition(\"spk_9\")[2].replace(\":\", \"\").replace(\"]\", \"\").replace('\\\\n', \"\")\n",
        "            spk1_str_f = spk1_str_f.rstrip(spk1_str_f[-1])\n",
        "            conversation = conversation + spk1_str_f\n",
        "          except:\n",
        "            pass \n",
        "\n",
        "        #sentiment analysis with AllenNLP's library for english copnversations\n",
        "        try:\n",
        "          #sentiment analysis with AllenNLP's library for english conversations \n",
        "          predictor = load_predictor(\"roberta-sst\")\n",
        "          preds = predictor.predict(conversation)\n",
        "        \n",
        "          #overall positivity score \n",
        "          positivity = \"Positivity score of the conversation : \" + str(preds['probs'][0] * 100) + \" %\"\n",
        "          #overall negativity score\n",
        "          negativity = \"Negativity score of the conversation : \" + str(preds['probs'][1] * 100) + \" %\"\n",
        "\n",
        "          #write the positivity score in the file\n",
        "          w.write(\"\\n\" + \"\\n\" + \"\\n\" + \"\\n\" + \"\\n\" + positivity + \"\\n\" + \"\\n\")\n",
        "          #write the negativity score in the file\n",
        "          w.write(negativity)\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ is \"__main__\":\n",
        "    \n",
        "    transcribe = boto3.client('transcribe',\n",
        "                          aws_access_key_id = \"#Your Access key\",\n",
        "                          aws_secret_access_key = \"#Your secret access key\",\n",
        "                          region_name = \"ap-south-1\")\n",
        "    audio_file_name = 'aws-hinglish-test.mp3'\n",
        "    s3_link = \"s3://hinglish-test/aws-hinglish-test.mp3\"\n",
        "    max_speakers = 10\n",
        "\n",
        "\n",
        "    transcript_json = amazon_transcribe_multi(audio_file_name,s3_link, max_speakers)\n",
        "\n",
        "    read_output(audio_file_name.split('.')[0].replace(\" \", \"\"), transcript_json)    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "transcription done\n",
            "aws-hinglish-test.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "roberta-rte is not a registered model.\n",
            "lerc is not a registered model.\n",
            "Plugin allennlp_models could not be loaded: No module named 'nltk.translate.meteor_score'\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJQ9wmpYeH0Q",
        "outputId": "dd4480da-d45a-4470-8e5d-b1682d3ce439"
      },
      "source": [
        "predictor = load_predictor(\"roberta-sst\")\n",
        "preds = predictor.predict(\"প্রবল কম্পন কেঁপে উঠল অসম , উত্তর৷\")\n",
        "        \n",
        "#overall positivity score \n",
        "positivity = \"Positivity score of the conversation : \" + str(preds['probs'][0] * 100) + \" %\"\n",
        "#overall negativity score\n",
        "negativity = \"Negativity score of the conversation : \" + str(preds['probs'][1] * 100) + \" %\"\n",
        "\n",
        "print(positivity)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "roberta-rte is not a registered model.\n",
            "lerc is not a registered model.\n",
            "Plugin allennlp_models could not be loaded: No module named 'nltk.translate.meteor_score'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Positivity score of the conversation : 60.99346876144409 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}